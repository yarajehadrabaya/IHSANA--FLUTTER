import 'dart:convert';
import 'dart:io';
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';
import 'package:path_provider/path_provider.dart'; // âœ… Ø¶Ø±ÙˆØ±ÙŠ Ù„Ø­ÙØ¸ Ù…Ù„ÙØ§Øª Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ± Ù…Ø¤Ù‚ØªØ§Ù‹

class MocaApiService {
  // Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø³Ø¨ÙŠØ³Ø§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
  static const String langUrl =
      "https://senior-moca2-moca-language-test.hf.space";
  static const String visionUrl =
      "https://senior-moca2-moca-vision-test.hf.space";
  static const String attentionUrl =
      "https://senior-moca2-moca-attention-test.hf.space";
  static const String memoryUrl =
      "https://senior-moca2-moca-memory-test.hf.space";
  static const String fluencyUrl =
      "https://senior-moca2-moca-fluency-test.hf.space";
  static const String abstractUrl =
      "https://senior-moca2-moca-abstraction-test.hf.space";
  static const String orientUrl =
      "https://senior-moca2-moca-orientation-test.hf.space";

  // ---------------------------------------------------------
  // ğŸš€ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¬Ø¯ÙŠØ¯: Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ± (Ø§Ù„Ø±Ø§Ø²Ø¨ÙŠØ±ÙŠ Ø¨Ø§ÙŠ)
  // ---------------------------------------------------------

  /// Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ¬Ù„Ø¨ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø±Ø§Ø²Ø¨ÙŠØ±ÙŠ ÙˆØªØ±Ø³Ù„Ù‡ ÙÙˆØ±Ø§Ù‹ Ù„Ù„Ù€ API Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
  /// [rpiIp]: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø§Ø²Ø¨ÙŠØ±ÙŠ (Ù…Ø«Ù„Ø§Ù‹ 192.168.1.15)
  /// [taskType]: Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© "image" Ø£Ùˆ "audio"
  /// [targetApi]: Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ù…Ù†Ø§Ø¯Ø§ØªÙ‡Ø§ Ø¨Ø¹Ø¯ Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ù…Ù„Ù (Ù…Ø«Ù„Ø§Ù‹ checkClock)
  Future<Map<String, dynamic>> processHardwareTask({
    required String rpiIp,
    required String taskType,
    required String functionName,
    String? extraParam, // Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù…Ø«Ù„ checkAttention ØªØ­ØªØ§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
  }) async {
    try {
      // 1. Ø·Ù„Ø¨ Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø±Ø§Ø²Ø¨ÙŠØ±ÙŠ Ø¨Ø§ÙŠ
      String hwEndpoint = taskType == "image" ? "/get-image" : "/get-audio";
      var hwResponse = await http.get(
        Uri.parse('http://$rpiIp:8000$hwEndpoint'),
      );

      if (hwResponse.statusCode == 200) {
        // 2. Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙ„Ù… Ù…Ø¤Ù‚ØªØ§Ù‹ ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„
        final dir = await getTemporaryDirectory();
        String fileName = taskType == "image"
            ? "hw_capture.jpg"
            : "hw_record.wav";
        File tempFile = File('${dir.path}/$fileName');
        await tempFile.writeAsBytes(hwResponse.bodyBytes);

        // 3. ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªÙ„Ù… Ø¥Ù„Ù‰ Ø§Ù„Ù€ API Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ÙÙŠ Hugging Face
        switch (functionName) {
          case 'checkClock':
            return await checkVision(tempFile.path, "clock");
          case 'checkCube':
            return await checkVision(tempFile.path, "cube");
          case 'checkNaming':
            return await checkNaming([tempFile.path]);
          case 'checkAttention':
            return await checkAttention(tempFile.path, extraParam ?? "");
          case 'checkMemory':
            return await checkMemory(tempFile.path);
          case 'checkFluency':
            return await checkFluency(tempFile.path);
          default:
            return {"score": 0, "analysis": "Ù…Ù‡Ù…Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"};
        }
      } else {
        return {"score": 0, "analysis": "Ø§Ù„Ø±Ø§Ø²Ø¨ÙŠØ±ÙŠ Ø¨Ø§ÙŠ Ù„Ù… ÙŠØ³ØªØ¬Ø¨ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­"};
      }
    } catch (e) {
      return {"score": 0, "analysis": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ±: $e"};
    }
  }

  // ---------------------------------------------------------
  // 1. Ù‚Ø³Ù… Ø§Ù„Ù„ØºØ© (Language)
  // ---------------------------------------------------------

  Future<Map<String, dynamic>> checkNaming(List<String> audioPaths) async {
    return await _post(
      url: "$langUrl/naming",
      fieldName: "audios",
      filePaths: audioPaths,
    );
  }

  Future<Map<String, dynamic>> checkSentence1(String audioPath) async {
    return await _post(
      url: "$langUrl/sentence1",
      fieldName: "audio",
      filePaths: [audioPath],
    );
  }

  Future<Map<String, dynamic>> checkSentence2(String audioPath) async {
    return await _post(
      url: "$langUrl/sentence2",
      fieldName: "audio",
      filePaths: [audioPath],
    );
  }

  // ---------------------------------------------------------
  // 2. Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
  // ---------------------------------------------------------

  Future<Map<String, dynamic>> checkTrails(String jsonPath) async {
    return await _post(
      url: "$visionUrl/trails",
      fieldName: "patient_file",
      filePaths: [jsonPath],
    );
  }

  Future<Map<String, dynamic>> checkVision(String path, String endpoint) async {
    return await _post(
      url: "$visionUrl/$endpoint",
      fieldName: "image",
      filePaths: [path],
      isImg: true,
    );
  }

  Future<Map<String, dynamic>> checkAttention(String path, String type) async {
    return await _post(
      url: "$attentionUrl/$type",
      fieldName: "audio",
      filePaths: [path],
    );
  }

  Future<Map<String, dynamic>> checkMemory(String path) async {
    return await _post(
      url: "$memoryUrl/check-memory",
      fieldName: "audio",
      filePaths: [path],
    );
  }

  Future<Map<String, dynamic>> checkFluency(String path) async {
    return await _post(
      url: "$fluencyUrl/check-fluency",
      fieldName: "audio",
      filePaths: [path],
    );
  }

  Future<Map<String, dynamic>> checkAbstraction(
    String path,
    int pairNum,
  ) async {
    String endpoint = pairNum == 1 ? "/pair1-transport" : "/pair2-measurement";
    return await _post(
      url: "$abstractUrl$endpoint",
      fieldName: "audio",
      filePaths: [path],
    );
  }

  Future<Map<String, dynamic>> checkOrientation({
    required String place,
    required String city,
    required List<String> audioPaths,
  }) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse("$orientUrl/check-orientation"),
      );
      request.fields['expected_place'] = place;
      request.fields['expected_city'] = city;
      List<String> keys = [
        'audio_weekday',
        'audio_month',
        'audio_year',
        'audio_place',
        'audio_city',
      ];
      for (int i = 0; i < audioPaths.length; i++) {
        request.files.add(
          await http.MultipartFile.fromPath(keys[i], audioPaths[i]),
        );
      }
      var response = await http.Response.fromStream(await request.send());
      return json.decode(response.body);
    } catch (e) {
      return {"score": 0, "analysis": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: $e"};
    }
  }

  // ğŸ› ï¸ Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ø§Ù…Ø© Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
  Future<Map<String, dynamic>> _post({
    required String url,
    required String fieldName,
    required List<String> filePaths,
    bool isImg = false,
  }) async {
    try {
      var request = http.MultipartRequest('POST', Uri.parse(url));
      for (var path in filePaths) {
        request.files.add(
          await http.MultipartFile.fromPath(
            fieldName,
            path,
            contentType: isImg
                ? MediaType('image', 'jpeg')
                : MediaType('audio', 'wav'),
          ),
        );
      }
      var res = await http.Response.fromStream(await request.send());
      if (res.statusCode == 200) {
        return json.decode(res.body);
      } else {
        return {"score": 0, "analysis": "Ø®Ø·Ø£ Ø³ÙŠØ±ÙØ±: ${res.statusCode}"};
      }
    } catch (e) {
      return {"score": 0, "analysis": "Ø®Ø·Ø£ Ø§ØªØµØ§Ù„: $e"};
    }
  }
}
