import 'dart:io';
import 'package:flutter/material.dart';
import 'package:ihsana/test/widgets/test_question_scaffold.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:http/http.dart' as http;

import '../../utils/moca_api_service.dart';
import '../../utils/test_session.dart';
import '../../session/session_context.dart';
import '../test_mode_selection_screen.dart';
import 'verbal_fluency_screen.dart';

class SentenceRepetitionTwoScreen extends StatefulWidget {
  const SentenceRepetitionTwoScreen({super.key});

  @override
  State<SentenceRepetitionTwoScreen> createState() =>
      _SentenceRepetitionTwoScreenState();
}

class _SentenceRepetitionTwoScreenState
    extends State<SentenceRepetitionTwoScreen> {
  final AudioPlayer _instructionPlayer = AudioPlayer();
  FlutterSoundRecorder? _recorder;
  final MocaApiService _apiService = MocaApiService();

  bool _isRecording = false;
  bool _hasRecorded = false;
  bool _isLoading = false;
  bool _isPlaying = false;
  String? _audioPath;

  @override
  void initState() {
    super.initState();

    if (SessionContext.testMode == TestMode.mobile) {
      _recorder = FlutterSoundRecorder()..openRecorder();
    }

    _playInstruction();
  }

  @override
  void dispose() {
    _instructionPlayer.dispose();
    _recorder?.closeRecorder();
    super.dispose();
  }

  // ğŸ”Š ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
  Future<void> _playInstruction() async {
    try {
      setState(() => _isPlaying = true);
      await _instructionPlayer.play(
        AssetSource('audio/sentance2.mp3'),
      );
      _instructionPlayer.onPlayerComplete.listen((_) {
        if (mounted) setState(() => _isPlaying = false);
      });
    } catch (e) {
      debugPrint("Audio error: $e");
      setState(() => _isPlaying = false);
    }
  }

  // ğŸ¤ Ø²Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ÙˆØ­Ø¯
  Future<void> _onRecordPressed() async {
    if (SessionContext.testMode == TestMode.hardware) {
      await _recordFromHardware();
    } else {
      await _recordFromMobile();
    }
  }

  // ================= ğŸ“± MOBILE =================
  Future<void> _recordFromMobile() async {
    if (_isRecording) {
      final path = await _recorder!.stopRecorder();
      setState(() {
        _isRecording = false;
        _hasRecorded = true;
        _audioPath = path;
      });
      debugPrint("âœ… Sentence 2 mobile recorded: $path");
    } else {
      final dir = await getTemporaryDirectory();
      await _instructionPlayer.stop();

      await _recorder!.startRecorder(
        toFile: '${dir.path}/sentence2_mobile.wav',
        codec: Codec.pcm16WAV,
        sampleRate: 16000,
        numChannels: 1,
      );

      setState(() {
        _isRecording = true;
        _hasRecorded = false;
        _audioPath = null;
      });
      debugPrint("ğŸ™ï¸ Sentence 2 mobile recording started");
    }
  }

  // ================= ğŸ–¥ï¸ HARDWARE =================
  Future<void> _recordFromHardware() async {
    setState(() => _isLoading = true);
    await _instructionPlayer.stop();

    try {
      final uri =
          Uri.parse('${SessionContext.raspberryBaseUrl}/get-audio');
      debugPrint("[HARDWARE] Requesting sentence 2 audio from $uri");

      final res = await http.get(uri).timeout(
            const Duration(seconds: 20),
          );

      if (res.statusCode != 200) {
        throw Exception("Hardware error ${res.statusCode}");
      }

      final dir = await getTemporaryDirectory();
      final file = File('${dir.path}/sentence2_hw.wav');
      await file.writeAsBytes(res.bodyBytes);

      setState(() {
        _audioPath = file.path;
        _hasRecorded = true;
      });

      debugPrint("âœ… Sentence 2 audio received from hardware");
    } catch (e) {
      debugPrint("âŒ Hardware error: $e");
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          const SnackBar(
            content: Text('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ'),
          ),
        );
      }
    } finally {
      if (mounted) setState(() => _isLoading = false);
    }
  }

  // ================= ğŸš€ SUBMIT =================
  Future<void> _submit() async {
    if (_audioPath == null) return;

    setState(() => _isLoading = true);
    try {
      final res = await _apiService.checkSentence2(_audioPath!);

      TestSession.sentence2Score = res['score'] ?? 0;

      debugPrint("=================================");
      debugPrint("ğŸ§  SENTENCE 2 RESULT");
      debugPrint("Score: ${res['score']}");
      debugPrint("Analysis: ${res['analysis']}");
      debugPrint("=================================");

      if (!mounted) return;

      Navigator.push(
        context,
        MaterialPageRoute(
          builder: (_) => const VerbalFluencyScreen(),
        ),
      );
    } catch (e) {
      debugPrint("Submit error: $e");
    } finally {
      if (mounted) setState(() => _isLoading = false);
    }
  }

  @override
  Widget build(BuildContext context) {
    final bool isHardware = SessionContext.testMode == TestMode.hardware;

    return Stack(
      children: [
        TestQuestionScaffold(
          title: 'ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¬Ù…Ù„Ø© (2/2)',
          instruction: isHardware
              ? 'Ø§Ø³ØªÙ…Ø¹ Ù„Ù„Ø¬Ù…Ù„Ø© Ø«Ù… Ø£Ø¹Ø¯Ù‡Ø§ Ø¨ÙˆØ¶ÙˆØ­ ÙÙŠ Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø§Ù„Ø¬Ù‡Ø§Ø².'
              : 'Ø§Ø³ØªÙ…Ø¹ Ù„Ù„Ø¬Ù…Ù„Ø© Ø«Ù… Ø£Ø¹Ø¯Ù‡Ø§ ÙƒÙ…Ø§ Ø³Ù…Ø¹ØªÙ‡Ø§.',
          content: Column(
            children: [
              ElevatedButton.icon(
                onPressed: _isPlaying ? null : _playInstruction,
                icon: const Icon(Icons.volume_up),
                label: const Text('Ø³Ù…Ø§Ø¹ Ø§Ù„Ø¬Ù…Ù„Ø©'),
              ),
              const SizedBox(height: 30),

              ElevatedButton.icon(
                onPressed:
                    (_isPlaying || _isLoading) ? null : _onRecordPressed,
                icon: Icon(
                  isHardware
                      ? Icons.settings_remote
                      : (_isRecording ? Icons.stop : Icons.mic),
                ),
                label: Text(
                  isHardware
                      ? 'Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ø¬Ù‡Ø§Ø²'
                      : (_isRecording
                          ? 'Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„'
                          : 'ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©'),
                ),
                style: ElevatedButton.styleFrom(
                  backgroundColor:
                      _isRecording ? Colors.red : Colors.blue,
                  foregroundColor: Colors.white,
                ),
              ),

              const SizedBox(height: 16),

              if (_hasRecorded && !_isRecording)
                const Text(
                  'âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©',
                  style: TextStyle(
                    color: Colors.green,
                    fontWeight: FontWeight.bold,
                  ),
                ),
            ],
          ),
          isNextEnabled:
              _hasRecorded && !_isRecording && !_isLoading,
          onNext: _submit,
          onEndSession: () =>
              Navigator.popUntil(context, (r) => r.isFirst),
        ),

        if (_isLoading)
          Container(
            color: Colors.black26,
            child: const Center(
              child: CircularProgressIndicator(),
            ),
          ),
      ],
    );
  }
}

