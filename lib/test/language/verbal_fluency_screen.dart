import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:ihsana/test/widgets/test_question_scaffold.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import '../../utils/moca_api_service.dart';
import '../../utils/test_session.dart';
import '../../session/session_context.dart'; // âœ… Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ Ø§Ù„Ù…Ø®ØªØ§Ø±
import '../test_mode_selection_screen.dart'; // âœ… Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù€ TestMode
import '../abstraction/abstraction_question_one_screen.dart';

class VerbalFluencyScreen extends StatefulWidget {
  const VerbalFluencyScreen({super.key});
  @override
  State<VerbalFluencyScreen> createState() => _VerbalFluencyScreenState();
}

class _VerbalFluencyScreenState extends State<VerbalFluencyScreen> {
  int _sec = 60;
  Timer? _t;
  final AudioPlayer _p = AudioPlayer();
  FlutterSoundRecorder? _r = FlutterSoundRecorder();
  final MocaApiService _apiService = MocaApiService();

  bool _isRun = false, _isFin = false, _load = false;
  String? _path;

  // âœ… Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù€ IP Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„Ø±Ø§ÙŠØ²Ø¨Ø±ÙŠ Ø¨Ø§ÙŠ
  final String rpiIp = "192.168.1.22";

  @override
  void initState() {
    super.initState();
    // Ù†ÙØªØ­ Ø§Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ† ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙˆØ¯ Ù‡Ùˆ Ø§Ù„Ø¬ÙˆØ§Ù„
    if (SessionContext.testMode == TestMode.mobile) {
      _r!.openRecorder();
    }
    _play();
  }

  Future<void> _play() async {
    try {
      await _p.play(AssetSource('audio/fluency.mp3'));
    } catch (e) {
      debugPrint("Error playing fluency audio: $e");
    }
  }

  // ğŸ¤ Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø© (ØªØ®ØªØ§Ø± Ø¨ÙŠÙ† Ù…Ø§ÙŠÙƒ Ø§Ù„Ø¬ÙˆØ§Ù„ Ø£Ùˆ Ù…Ø§ÙŠÙƒ Ø§Ù„Ø±Ø§ÙŠØ²Ø¨Ø±ÙŠ)
  Future<void> _start() async {
    if (SessionContext.testMode == TestMode.hardware) {
      // ğŸ–¥ï¸ Ù…Ø³Ø§Ø± Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ±
      setState(() {
        _isRun = true;
        _isFin = false;
        _sec = 60;
        _load = true; // Ù†ÙØ¸Ù‡Ø± Ù„ÙˆØ¯ÙŠÙ†Ø¬ Ø®ÙÙŠÙ Ù„Ø£Ù† Ø§Ù„Ø·Ù„Ø¨ Ø³ÙŠØ¨Ù‚Ù‰ Ù…Ø¹Ù„Ù‚Ø§Ù‹ Ø¯Ù‚ÙŠÙ‚Ø©
      });

      _startTimer(); // Ù†Ø´ØºÙ„ Ø§Ù„Ù…Ø¤Ù‚Øª ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ù„Ù„Ù…Ø±ÙŠØ¶

      try {
        debugPrint("--- [HARDWARE MODE] Ø¬Ø§Ø±ÙŠ Ø·Ù„Ø¨ ØªØ³Ø¬ÙŠÙ„ 60 Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ø±Ø§ÙŠØ²Ø¨Ø±ÙŠ ---");
        // Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø±Ø§ÙŠØ²Ø¨Ø±ÙŠ ÙŠØ³Ø¬Ù„ (ØªØ£ÙƒØ¯ÙŠ Ø£Ù† Ø§Ù„Ø±Ø§ÙŠØ²Ø¨Ø±ÙŠ Ù…Ø¨Ø±Ù…Ø¬ Ù„ÙŠØ³Ø¬Ù„ Ù„ÙØªØ±Ø© Ø·ÙˆÙŠÙ„Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„)
        final result = await _apiService.processHardwareTask(
          rpiIp: rpiIp,
          taskType: "audio",
          functionName: "NONE",
        );

        if (result.containsKey('tempPath')) {
          _path = result['tempPath'];
          setState(() {
            _isFin = true;
            _isRun = false;
          });
        }
      } catch (e) {
        debugPrint("Error fetching audio from RPi: $e");
        setState(() { _isRun = false; _isFin = false; });
      } finally {
        setState(() => _load = false);
      }
    } else {
      // ğŸ“± Ù…Ø³Ø§Ø± Ø§Ù„Ø¬ÙˆØ§Ù„: Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ø§Ù„Ù…Ø§ÙŠÙƒ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ
      final dir = await getTemporaryDirectory();
      _path = '${dir.path}/flu.wav';
      await _r!.startRecorder(
        toFile: _path,
        codec: Codec.pcm16WAV,
        sampleRate: 16000,
        numChannels: 1,
      );
      setState(() {
        _isRun = true;
        _isFin = false;
        _sec = 60;
      });
      _startTimer();
    }
  }

  // ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù…Ø¤Ù‚Øª Ø§Ù„Ø²Ù…Ù†ÙŠ
  void _startTimer() {
    _t = Timer.periodic(const Duration(seconds: 1), (timer) {
      if (_sec == 0) {
        timer.cancel();
        if (SessionContext.testMode == TestMode.mobile) {
          _stopMobileRecording();
        }
      } else {
        setState(() => _sec--);
      }
    });
  }

  Future<void> _stopMobileRecording() async {
    await _r!.stopRecorder();
    setState(() {
      _isRun = false;
      _isFin = true;
    });
  }

  Future<void> _submit() async {
    if (_path == null) return;
    setState(() => _load = true);
    try {
      final res = await _apiService.checkFluency(_path!);
      TestSession.fluencyScore = res['score'] ?? 0;
      debugPrint("--- Fluency Score: ${TestSession.fluencyScore} ---");
      if (mounted) {
        Navigator.push(
          context,
          MaterialPageRoute(builder: (_) => const AbstractionQuestionOneScreen()),
        );
      }
    } catch (e) {
      debugPrint("Error: $e");
    } finally {
      if (mounted) setState(() => _load = false);
    }
  }

  @override
  void dispose() {
    _t?.cancel();
    _p.dispose();
    _r?.closeRecorder();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    bool isHardware = SessionContext.testMode == TestMode.hardware;

    return Stack(
      children: [
        TestQuestionScaffold(
          title: 'Ø§Ù„Ø·Ù„Ø§Ù‚Ø© Ø§Ù„Ù„ÙØ¸ÙŠØ©',
          content: Column(
            children: [
              // Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„Ù…Ø¤Ù‚Øª
              Container(
                padding: const EdgeInsets.all(30),
                decoration: BoxDecoration(
                  shape: BoxShape.circle,
                  border: Border.all(color: _isRun ? Colors.red : Colors.blue, width: 5),
                ),
                child: Text(
                  "$_sec",
                  style: const TextStyle(fontSize: 64, fontWeight: FontWeight.bold),
                ),
              ),
              const SizedBox(height: 10),
              const Text("Ø«Ø§Ù†ÙŠØ© Ù…ØªØ¨Ù‚ÙŠØ©", style: TextStyle(fontSize: 18, color: Colors.grey)),
              
              const SizedBox(height: 40),
              
              ElevatedButton.icon(
                onPressed: _isRun || _isFin || _load ? null : _start,
                style: ElevatedButton.styleFrom(
                  backgroundColor: isHardware ? Colors.orange : Colors.blue,
                  padding: const EdgeInsets.symmetric(horizontal: 40, vertical: 15),
                ),
                icon: Icon(isHardware ? Icons.settings_input_component : Icons.mic),
                label: Text(isHardware ? "Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ø¬Ù‡Ø§Ø²" : "Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©"),
              ),
              
              if (_isFin && !_load)
                const Padding(
                  padding: EdgeInsets.only(top: 20),
                  child: Text("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙˆÙ‚ØªØŒ Ø§Ø¶ØºØ· Ù…ØªØ§Ø¨Ø¹Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„", 
                    style: TextStyle(color: Colors.green, fontWeight: FontWeight.bold)),
                ),
            ],
          ),
          isNextEnabled: _isFin && !_load,
          onNext: _submit,
          onEndSession: () => Navigator.popUntil(context, (r) => r.isFirst),
        ),
        if (_load)
          Container(
            color: Colors.black26,
            child: const Center(
              child: Column(
                mainAxisSize: MainAxisSize.min,
                children: [
                  CircularProgressIndicator(),
                  SizedBox(height: 16),
                  Text("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª...", style: TextStyle(color: Colors.white, fontWeight: FontWeight.bold)),
                ],
              ),
            ),
          ),
      ],
    );
  }
}